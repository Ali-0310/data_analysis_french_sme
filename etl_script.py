import pandas as pd
import sqlite3
import requests
import io
from datetime import datetime

def extract_data():
    """√âtape 1: Extraction des donn√©es depuis les URLs"""
    print("üì• √âtape 1: Extraction des donn√©es...")
    
    # URLs des fichiers de donn√©es
    url_ventes = "https://docs.google.com/spreadsheets/d/e/2PACX-1vSawI56WBC64foMT9pKCiY594fBZk9Lyj8_bxfgmq-8ck_jw1Z49qDeMatCWqBxehEVoM6U1zdYx73V/pub?gid=760830694&single=true&output=csv"
    url_produits = "https://docs.google.com/spreadsheets/d/e/2PACX-1vSawI56WBC64foMT9pKCiY594fBZk9Lyj8_bxfgmq-8ck_jw1Z49qDeMatCWqBxehEVoM6U1zdYx73V/pub?gid=0&single=true&output=csv"
    url_magasins = "https://docs.google.com/spreadsheets/d/e/2PACX-1vSawI56WBC64foMT9pKCiY594fBZk9Lyj8_bxfgmq-8ck_jw1Z49qDeMatCWqBxehEVoM6U1zdYx73V/pub?gid=714623615&single=true&output=csv"
    
    try:
        # Extraction des donn√©es ventes
        response_ventes = requests.get(url_ventes)
        response_ventes.raise_for_status()
        df_ventes = pd.read_csv(io.StringIO(response_ventes.content.decode('utf-8')))
        print(f"‚úÖ Donn√©es ventes extraites: {len(df_ventes)} lignes")
        
        # Extraction des donn√©es produits
        response_produits = requests.get(url_produits)
        response_produits.raise_for_status()
        df_produits = pd.read_csv(io.StringIO(response_produits.content.decode('utf-8')))
        print(f"‚úÖ Donn√©es produits extraites: {len(df_produits)} lignes")
        
        # Extraction des donn√©es magasins
        response_magasins = requests.get(url_magasins)
        response_magasins.raise_for_status()
        df_magasins = pd.read_csv(io.StringIO(response_magasins.content.decode('utf-8')))
        print(f"‚úÖ Donn√©es magasins extraites: {len(df_magasins)} lignes")
        
        return df_ventes, df_produits, df_magasins
        
    except requests.RequestException as e:
        print(f"‚ùå Erreur lors de l'extraction: {e}")
        return None, None, None

def transform_data(df_ventes, df_produits, df_magasins):
    """√âtape 2: Transformation des donn√©es selon le sch√©ma MCD"""
    print("\nüîÑ √âtape 2: Transformation des donn√©es...")
    
    # Transformation des donn√©es temporelles (DIM_TEMPS)
    print("üìÖ Transformation des donn√©es temporelles...")
    df_ventes['Date'] = pd.to_datetime(df_ventes['Date'])
    
    df_dates = pd.DataFrame({
        'DATE_COMPLETE': df_ventes['Date'],
        'JOUR_SEMAINE': pd.to_datetime(df_ventes['Date']).dt.day_name(),
        'MOIS': pd.to_datetime(df_ventes['Date']).dt.month_name(),
        'ANNEE': pd.to_datetime(df_ventes['Date']).dt.year,
        'TRIMESTRE': pd.to_datetime(df_ventes['Date']).dt.quarter
    })
    
    # Transformation des donn√©es produits (DIM_PRODUITS)
    print("üì¶ Transformation des donn√©es produits...")
    df_produits_transformed = df_produits.rename(columns={
        'ID R√©f√©rence produit': 'ID_REFERENCE_PRODUIT',
        'Nom': 'NOM_PRODUIT',
        'Prix': 'PRIX_UNITAIRE',
        'Stock': 'STOCK_DISPONIBLE'
    })
    
    # Transformation des donn√©es magasins (DIM_MAGASINS)
    print("üè™ Transformation des donn√©es magasins...")
    df_magasins_transformed = df_magasins.rename(columns={
        'ID Magasin': 'ID_MAGASIN',
        'Ville': 'VILLE',
        'Nombre de salari√©s': 'NOMBRE_SALARIES'
    })
    
    # Ajout des colonnes calcul√©es pour les magasins
    region_mapping = {
        'Paris': '√éle-de-France',
        'Marseille': 'Provence-Alpes-C√¥te d\'Azur',
        'Lyon': 'Auvergne-Rh√¥ne-Alpes',
        'Bordeaux': 'Nouvelle-Aquitaine',
        'Lille': 'Hauts-de-France',
        'Nantes': 'Pays de la Loire',
        'Strasbourg': 'Grand Est'
    }
    
    df_magasins_transformed['REGION'] = df_magasins_transformed['VILLE'].map(region_mapping)
    df_magasins_transformed['TAILLE_MAGASIN'] = df_magasins_transformed['NOMBRE_SALARIES'].apply(
        lambda x: 'Petit' if x < 5 else 'Moyen' if x <= 10 else 'Grand'
    )
    
    # Transformation des donn√©es de ventes (FAIT_VENTES)
    print("üí∞ Transformation des donn√©es de ventes...")
    
    # Cr√©ation du mapping date vers ID_TEMPS
    date_to_id = dict(zip(df_dates['DATE_COMPLETE'], range(1, len(df_dates) + 1)))
    
 
    
    # Cr√©ation de la table de faits
    df_faits = df_ventes.copy()
    df_faits['ID_TEMPS'] = df_faits['Date'].map(date_to_id)
    df_faits['ID_MAGASIN'] = df_faits['ID Magasin']
    df_faits['QUANTITE_VENDUE'] = df_faits['Quantit√©']
    df_faits['ID_REFERENCE_PRODUIT'] = df_faits['ID R√©f√©rence produit']
    
    # Calcul du montant de vente
    prix_produits = dict(zip(df_produits_transformed['ID_REFERENCE_PRODUIT'], df_produits_transformed['PRIX_UNITAIRE']))
    df_faits['MONTANT_VENTE'] = df_faits['ID R√©f√©rence produit'].map(prix_produits) * df_faits['QUANTITE_VENDUE']
    
    # S√©lection des colonnes finales pour FAIT_VENTES
    df_faits_final = df_faits[['ID_TEMPS', 'ID_REFERENCE_PRODUIT', 'ID_MAGASIN', 'QUANTITE_VENDUE', 'MONTANT_VENTE']]
    
    print("‚úÖ Transformation termin√©e!")
    return df_dates, df_produits_transformed, df_magasins_transformed, df_faits_final

def load_data_conditionally(df_dates, df_produits, df_magasins, df_faits):
    """√âtape 3: Ingestion conditionnelle des donn√©es"""
    print("\nüíæ √âtape 3: Ingestion conditionnelle des donn√©es...")
    
    try:
        # Connexion √† la base de donn√©es
        conn = sqlite3.connect('./data/sales_analysis.db')
        cursor = conn.cursor()
        
        # Fonction pour v√©rifier si des donn√©es existent d√©j√†
        def data_exists(table_name, check_column, check_values):
            placeholders = ','.join(['?' for _ in check_values])
            query = f"SELECT COUNT(*) FROM {table_name} WHERE {check_column} IN ({placeholders})"
            cursor.execute(query, check_values)
            return cursor.fetchone()[0] > 0
        
        # Ingestion conditionnelle DIM_TEMPS
        print("üìÖ Ingestion DIM_TEMPS...")
        if not data_exists('DIM_TEMPS', 'DATE_COMPLETE', df_dates['DATE_COMPLETE'].dt.strftime('%Y-%m-%d').tolist()):
            df_dates.to_sql('DIM_TEMPS', conn, if_exists='append', index=False)
            print(f"‚úÖ {len(df_dates)} nouvelles dates ins√©r√©es")
        else:
            print("‚ÑπÔ∏è Donn√©es temporelles d√©j√† pr√©sentes")
        
        # Ingestion conditionnelle DIM_PRODUITS
        print("üì¶ Ingestion DIM_PRODUITS...")
        if not data_exists('DIM_PRODUITS', 'ID_REFERENCE_PRODUIT', df_produits['ID_REFERENCE_PRODUIT'].tolist()):
            df_produits.to_sql('DIM_PRODUITS', conn, if_exists='append', index=False)
            print(f"‚úÖ {len(df_produits)} nouveaux produits ins√©r√©s")
        else:
            print("‚ÑπÔ∏è Donn√©es produits d√©j√† pr√©sentes")
        
        # Ingestion conditionnelle DIM_MAGASINS
        print("üè™ Ingestion DIM_MAGASINS...")
        if not data_exists('DIM_MAGASINS', 'ID_MAGASIN', df_magasins['ID_MAGASIN'].tolist()):
            df_magasins.to_sql('DIM_MAGASINS', conn, if_exists='append', index=False)
            print(f"‚úÖ {len(df_magasins)} nouveaux magasins ins√©r√©s")
        else:
            print("‚ÑπÔ∏è Donn√©es magasins d√©j√† pr√©sentes")
        
        # Ingestion conditionnelle FAIT_VENTES
        print("üí∞ Ingestion FAIT_VENTES...")
        # V√©rification bas√©e sur la combinaison des cl√©s
        existing_ventes = pd.read_sql("""
            SELECT ID_TEMPS, ID_REFERENCE_PRODUIT, ID_MAGASIN, COUNT(*) as count 
            FROM FAIT_VENTES 
            GROUP BY ID_TEMPS, ID_REFERENCE_PRODUIT, ID_MAGASIN
        """, conn)
        
        if len(existing_ventes) == 0:
            df_faits.to_sql('FAIT_VENTES', conn, if_exists='append', index=False)
            print(f"‚úÖ {len(df_faits)} nouvelles ventes ins√©r√©es")
        else:
            print("‚ÑπÔ∏è Donn√©es de ventes d√©j√† pr√©sentes")
        
        # Validation finale
        print("\nüìä Validation des donn√©es:")
        cursor.execute("SELECT COUNT(*) FROM DIM_TEMPS")
        print(f"- DIM_TEMPS: {cursor.fetchone()[0]} enregistrements")
        
        cursor.execute("SELECT COUNT(*) FROM DIM_PRODUITS")
        print(f"- DIM_PRODUITS: {cursor.fetchone()[0]} enregistrements")
        
        cursor.execute("SELECT COUNT(*) FROM DIM_MAGASINS")
        print(f"- DIM_MAGASINS: {cursor.fetchone()[0]} enregistrements")
        
        cursor.execute("SELECT COUNT(*) FROM FAIT_VENTES")
        print(f"- FAIT_VENTES: {cursor.fetchone()[0]} enregistrements")
        
        conn.commit()
        conn.close()
        print("\n‚úÖ Ingestion termin√©e avec succ√®s!")
        
    except Exception as e:
        print(f"‚ùå Erreur lors de l'ingestion: {e}")
        if 'conn' in locals():
            conn.close()

def main():
    """Pipeline ETL principal"""
    print("üöÄ D√©marrage du pipeline ETL...")
    
    # √âtape 1: Extraction
    df_ventes, df_produits, df_magasins = extract_data()
    if df_ventes is None:
        print("‚ùå √âchec de l'extraction. Arr√™t du pipeline.")
        return
    
    # √âtape 2: Transformation
    df_dates, df_produits_transformed, df_magasins_transformed, df_faits = transform_data(
        df_ventes, df_produits, df_magasins
    )
    
    # √âtape 3: Ingestion conditionnelle
    load_data_conditionally(df_dates, df_produits_transformed, df_magasins_transformed, df_faits)
    
    print("\nüéâ Pipeline ETL termin√© avec succ√®s!")

if __name__ == "__main__":
    main() 